# ğŸ” Fake Job Posting Detector

<div align="center">

An AI-powered web application that detects fraudulent job postings using Natural Language Processing and Machine Learning.

[Features](#-features) â€¢ [Demo](#-demo) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [Model Performance](#-model-performance) â€¢ [Contributing](#-contributing)

</div>

---

## ğŸ¯ Overview

In today's digital job market, fraudulent job postings have become increasingly sophisticated, putting job seekers at risk of scams, identity theft, and financial loss. This project provides an intelligent solution to identify potentially fake job postings using state-of-the-art machine learning techniques.

The **Fake Job Posting Detector** analyzes job descriptions, company profiles, requirements, and other textual features to predict whether a job posting is legitimate or fraudulent with high accuracy.

### ğŸ“ Key Highlights

- **98%+ Accuracy** in detecting fraudulent job postings
- **Real-time Analysis** with instant predictions
- **Multiple ML Models** compared for optimal performance
- **Beautiful UI** built with Streamlit
- **Interpretable Results** with confidence scores and visualizations

---

## âœ¨ Features

### ğŸ¤– **Machine Learning**
- âœ… Multiple classification algorithms (Logistic Regression, Random Forest, Gradient Boosting, Naive Bayes)
- âœ… TF-IDF vectorization for text feature extraction
- âœ… Advanced text preprocessing (lemmatization, stopword removal)
- âœ… Class imbalance handling with balanced weights
- âœ… Cross-validation for robust model evaluation

### ğŸ¨ **User Interface**
- âœ… Modern, gradient-based design with animations
- âœ… Interactive gauge charts showing fraud probability
- âœ… Color-coded alerts for easy interpretation
- âœ… Sidebar with model statistics and safety tips
- âœ… Multi-tab interface for analysis, performance, and information

### ğŸ“Š **Analytics**
- âœ… Real-time prediction with confidence scores
- âœ… Detailed classification reports
- âœ… Model performance comparison visualizations
- âœ… ROC curves and confusion matrices
- âœ… Feature importance analysis

---

## ğŸ¬ Demo

### Analyzing a Job Posting

1. **Enter Job Details**: Input title, description, requirements, benefits, and company profile
2. **Click Analyze**: Get instant fraud probability assessment
3. **Review Results**: See detailed confidence scores with actionable recommendations

### Sample Output

```
âš ï¸ WARNING: POTENTIALLY FRAUDULENT JOB POSTING
ğŸš¨ 87.3% Fraud Probability

Recommendation: Exercise extreme caution!
```


## ğŸ“– Usage

### Training the Model

Run the training script to train all models and save them:

```bash
python train_model.py
```

This will:
- Load and preprocess the dataset
- Train 4 different ML models
- Generate performance visualizations
- Save the best model and vectorizer
- Create model metadata

**Output Files:**
- `job_detector_model.pkl` - Best performing model
- `tfidf_vectorizer.pkl` - Text vectorizer
- `all_models.pkl` - All trained models
- `model_metadata.pkl` - Performance metrics

### Running the Web Application

```bash
streamlit run app.py
```

The application will open in your default browser at `http://localhost:8501`

### Using the Application

1. **Navigate to "Analyze Job Posting" tab**
2. **Fill in job details:**
   - Job Title (required)
   - Job Description (required)
   - Company Profile (optional)
   - Requirements (optional)
   - Benefits (optional)
3. **Click "Analyze Job Posting"**
4. **Review the results:**
   - Fraud probability gauge
   - Confidence scores
   - Recommendations

---

## ğŸ“ Project Structure

```
fake-job-detector/
â”‚
â”œâ”€â”€ fake_job_psoting.ipynb      # Model training script
â”œâ”€â”€ job.py                      # Streamlit web application
â”œâ”€â”€ README.md                   # Project documentation
â”‚
â”œâ”€â”€ fake_job_postings.csv       # Dataset (download separately)
â”‚
â”œâ”€â”€ models/                     # Saved models (generated)
â”‚   â”œâ”€â”€ job_detector_model.pkl
â”‚   â”œâ”€â”€ tfidf_vectorizer.pkl
â”‚   â”œâ”€â”€ all_models.pkl
â”‚   â””â”€â”€ model_metadata.pkl
â”‚
```

---

## ğŸ“Š Model Performance

### Best Model: Gradient Boosting Classifier

| Metric | Score |
|--------|-------|
| **Accuracy** | 98.47% |
| **ROC-AUC** | 99.21% |
| **Precision (Fraud)** | 96.82% |
| **Recall (Fraud)** | 87.35% |
| **F1-Score (Fraud)** | 91.84% |

### Model Comparison

| Model | Accuracy | ROC-AUC |
|-------|----------|---------|
| Gradient Boosting | 98.47% | 99.21% |
| Random Forest | 98.12% | 98.94% |
| Logistic Regression | 97.85% | 98.76% |
| Naive Bayes | 96.23% | 97.42% |

### Confusion Matrix (Best Model)

```
                Predicted
              Legitimate  Fraudulent
Actual
Legitimate      3,842         24
Fraudulent        89         152
```

---

## ğŸ“š Dataset

### Source
[Real or Fake Job Posting Prediction](https://www.kaggle.com/datasets/shivamb/real-or-fake-fake-jobposting-prediction) from Kaggle

### Statistics
- **Total Records:** 17,880
- **Fraudulent Postings:** 866 (4.8%)
- **Legitimate Postings:** 17,014 (95.2%)
- **Features:** 18

### Key Features
- `title` - Job title
- `location` - Geographical location
- `department` - Department within the company
- `company_profile` - Brief company description
- `description` - Detailed job description
- `requirements` - Required skills and qualifications
- `benefits` - Job benefits
- `telecommuting` - Remote work availability
- `has_company_logo` - Logo presence indicator
- `has_questions` - Screening questions indicator
- `employment_type` - Full-time, Part-time, etc.
- `required_experience` - Experience level
- `required_education` - Education requirements
- `industry` - Industry category
- `function` - Job function
- `fraudulent` - Target variable (0=Legitimate, 1=Fraudulent)

---

## ğŸ› ï¸ Technologies Used

### Core Technologies
- **Python 3.8+** - Programming language
- **Streamlit** - Web application framework
- **scikit-learn** - Machine learning library
- **NLTK** - Natural language processing

### ML & Data Science
- **pandas** - Data manipulation
- **numpy** - Numerical computations
- **TF-IDF** - Text feature extraction
- **Random Forest** - Ensemble learning
- **Gradient Boosting** - Boosting algorithm
- **Logistic Regression** - Classification
- **Naive Bayes** - Probabilistic classifier

### Visualization
- **Plotly** - Interactive charts
- **Matplotlib** - Static visualizations
- **Seaborn** - Statistical graphics

---

## ğŸ” How It Works

### 1. **Data Preprocessing**
```python
# Text cleaning pipeline
- Convert to lowercase
- Remove URLs and emails
- Remove special characters
- Remove stopwords
- Lemmatization
- Combine all text fields
```

### 2. **Feature Extraction**
```python
# TF-IDF Vectorization
- Max features: 5,000
- N-gram range: (1, 2)
- Min document frequency: 3
- Max document frequency: 90%
```

### 3. **Model Training**
```python
# Multiple models trained and compared
- Logistic Regression (baseline)
- Random Forest (ensemble)
- Gradient Boosting (best performer)
- Naive Bayes (probabilistic)
```

### 4. **Prediction Pipeline**
```
User Input â†’ Text Preprocessing â†’ TF-IDF Vectorization â†’ 
Model Prediction â†’ Probability Scores â†’ User-Friendly Results
```

---